# Epic 13: Agent Orchestrator - Status & Test Plan

**Date:** 2025-10-17  
**Overall Status:** âš ï¸ **95% Complete - Testing Issues Found**  
**Test Results:** 14/26 passing (54%), 12 timeouts

---

## âœ… **What's Complete**

### **Core Implementation (100%)**
- âœ… `agent-orchestrator.ts` (358 lines) - Agent reasoning loop
- âœ… `agent-tools.ts` (352 lines) - 6 core tools
- âœ… `agent-memory.ts` (248 lines) - Conversation memory
- âœ… `agent.ts` (277 lines) - API routes
- âœ… Database migrations (020_agent_conversations.sql, 021_agent_tool_calls.sql)
- âœ… Schema integration (agentConversations, agentToolCalls tables)
- âœ… Routes registered in index.ts

### **Documentation (100%)**
- âœ… `EPIC13_DELIVERY_COMPLETE.md` - Delivery summary
- âœ… `EPIC13_TEST_GUIDE.md` - Test guide
- âœ… `EPIC13_PHASE1_COMPLETE.md` - Phase 1 report
- âœ… `docs/architecture/agent-orchestrator.md` - Architecture
- âœ… `docs/architecture/tool-development-guide.md` - Tool development

### **Frontend Integration (100%)**
- âœ… Feature flag support (`FF_AGENT_ORCHESTRATOR_V1`)
- âœ… Backward compatibility with workflow system
- âœ… Graceful fallback on errors

---

## âš ï¸ **What's Incomplete/Problematic**

### **Test Suite (54% Passing)**

**Passing Tests (14/26):**
- âœ… Health check
- âœ… Meta-request detection (5/5 scenarios)
- âœ… Filler word handling (1/3 scenarios)
- âœ… Natural variations (1/3 scenarios)
- âœ… Error handling (3/3 scenarios)
- âœ… Memory reset
- âœ… Iteration limits

**Failing Tests (12/26):**
- âŒ Affirmative flexibility (3/3 timeout)
- âŒ Granularity detection (2/3 timeout)
- âŒ Filler word handling (2/3 timeout)
- âŒ Natural variations (2/3 timeout)
- âŒ Conversation history retrieval (assertion fail)
- âŒ Performance (1/1 timeout)

**Root Causes:**
1. **Test timeout (5s):** Tests are calling real OpenAI API (~8-10s per call)
2. **Missing mocks:** Tests expect instant responses, getting real API latency
3. **Conversation history:** Test timing issue (assertion before data saved)

---

## ðŸ”§ **Issues to Fix**

### **Issue 1: Test Timeouts**

**Problem:** Tests timeout at 5s because they're calling real OpenAI API.

**Fix Options:**

**Option A: Increase Timeout (Quick Fix)**
```typescript
// In agent-orchestrator.test.ts
describe('Epic 13: Agent Orchestrator', () => {
  vi.setConfig({ testTimeout: 30000 }); // 30 seconds
  
  // ... tests
});
```

**Option B: Mock OpenAI Calls (Better)**
```typescript
import { vi } from 'vitest';

vi.mock('../src/services/llm-orchestrator', () => ({
  callOpenAI: vi.fn().mockResolvedValue({
    content: JSON.stringify({ action: 'confirmWithUser', message: '...' }),
    model: 'gpt-4o-mini',
    tokens: 100,
    costUsd: 0.01,
    durationMs: 500,
  }),
}));
```

**Option C: Separate Integration vs Unit Tests**
- **Unit tests:** Mock all external calls (fast, < 1s)
- **Integration tests:** Real API calls with 30s timeout

**Recommendation:** **Option C** (separate unit and integration tests)

---

### **Issue 2: Conversation History Test Failure**

**Problem:** Test expects conversation history immediately after chat, but async write may not complete.

**Fix:**
```typescript
// In agent-orchestrator.test.ts, line 433-436
it('should retrieve conversation history', async () => {
  // 1. Send message
  await fetch('/api/agent/chat', {
    method: 'POST',
    body: JSON.stringify({ userId, message: 'test' }),
  });
  
  // 2. Wait for async write to complete
  await new Promise(resolve => setTimeout(resolve, 1000)); // Wait 1s
  
  // 3. Retrieve history
  const response = await fetch('/api/agent/memory/test-user');
  const data = await response.json();
  
  expect(response.status).toBe(200);
  expect(data.history).toBeDefined();
  expect(data.history.length).toBeGreaterThan(0);
});
```

---

## ðŸ“‹ **Comprehensive Test Plan**

### **Phase 1: Fix Existing Tests (1-2h)**

**Tasks:**
1. **Separate unit vs integration tests**
   - `agent-orchestrator.unit.test.ts` - Mocked, fast (<5s total)
   - `agent-orchestrator.integration.test.ts` - Real API, slow (30s timeout)

2. **Mock OpenAI in unit tests**
   - Mock `callOpenAI` to return instant responses
   - Test agent logic, not LLM responses

3. **Fix conversation history test**
   - Add 1s delay before asserting
   - Or make storage synchronous for tests

4. **Increase integration test timeout**
   - Set `testTimeout: 30000` for integration tests

**Expected Outcome:** 26/26 tests passing

---

### **Phase 2: Add Missing Test Coverage (2-3h)**

**Current coverage gaps:**

#### **A. Tool Execution Tests**
```typescript
describe('Tool Execution', () => {
  it('should call searchTopics tool correctly', async () => {
    // Test tool parameters, response parsing
  });
  
  it('should call detectGranularity tool correctly', async () => {
    // Test granularity detection
  });
  
  it('should call getUserProgress tool correctly', async () => {
    // Test progress retrieval
  });
  
  it('should call generateContent tool correctly', async () => {
    // Test content generation trigger
  });
  
  it('should call confirmWithUser tool correctly', async () => {
    // Test confirmation flow
  });
  
  it('should call storeDecision tool correctly', async () => {
    // Test decision storage
  });
});
```

#### **B. Error Handling Tests**
```typescript
describe('Advanced Error Handling', () => {
  it('should handle tool timeout (10s limit)', async () => {
    // Mock slow tool response
  });
  
  it('should handle tool error gracefully', async () => {
    // Mock tool throwing error
  });
  
  it('should handle malformed LLM response', async () => {
    // Mock invalid JSON from LLM
  });
  
  it('should handle iteration limit (5 max)', async () => {
    // Mock agent looping
  });
  
  it('should handle memory storage failure', async () => {
    // Mock DB error
  });
});
```

#### **C. Conversation Flow Tests**
```typescript
describe('Conversation Flows', () => {
  it('should handle multi-turn conversation', async () => {
    // User: "I want to learn physics"
    // Agent: "Let me help with physics. ..."
    // User: "yes"
    // Agent: [generates content]
  });
  
  it('should handle rejection with correction', async () => {
    // User: "I want to learn physics"
    // Agent: "Let me help with physics. ..."
    // User: "no, I meant chemistry"
    // Agent: "Got it, chemistry instead. ..."
  });
  
  it('should handle refinement loop', async () => {
    // User: "science"
    // Agent: "Which area? Physics, Chemistry, Biology?"
    // User: "physics"
    // Agent: "Which area of physics? ..."
    // User: "quantum mechanics"
    // Agent: "Great, quantum mechanics. ..."
  });
});
```

#### **D. Performance Tests**
```typescript
describe('Performance', () => {
  it('should respond in <5s for simple queries', async () => {
    // Test with meta-requests (should be fast)
  });
  
  it('should handle concurrent requests', async () => {
    // Send 10 requests simultaneously
  });
  
  it('should track tool execution time', async () => {
    // Verify metrics recorded
  });
});
```

#### **E. Security Tests**
```typescript
describe('Security', () => {
  it('should sanitize user input', async () => {
    // Test SQL injection attempts
  });
  
  it('should validate userId format', async () => {
    // Test malformed UUIDs
  });
  
  it('should prevent prompt injection', async () => {
    // Test adversarial inputs
  });
  
  it('should respect rate limits', async () => {
    // Test excessive requests
  });
});
```

---

### **Phase 3: Manual Integration Testing (2-3h)**

**Test Environment:**
```bash
# Terminal 1: Start API with agent enabled
cd api
FF_AGENT_ORCHESTRATOR_V1=true \
OPENAI_API_KEY=sk-... \
npm run dev

# Terminal 2: Run manual tests
```

#### **Test 1: Basic Chat Flow**
```bash
# 1. Health check
curl http://localhost:8080/api/agent/health | jq

# 2. Simple query
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-1", "message": "I want to learn quantum physics"}'

# Expected: Agent uses searchTopics, detectGranularity, responds naturally

# 3. Follow-up confirmation
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-1", "message": "yes"}'

# Expected: Agent confirms and suggests next steps

# 4. Retrieve history
curl http://localhost:8080/api/agent/memory/test-user-1 | jq

# Expected: 2+ messages in history
```

#### **Test 2: Subject Refinement Flow**
```bash
# 1. Broad subject
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-2", "message": "I want to learn science"}'

# Expected: Agent asks for refinement (Physics? Chemistry? Biology?)

# 2. Narrow down
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-2", "message": "physics"}'

# Expected: Agent narrows further (Astrophysics? Quantum? Classical?)

# 3. Final selection
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-2", "message": "quantum mechanics"}'

# Expected: Agent confirms specific topic
```

#### **Test 3: Meta-Request Detection**
```bash
# 1. Start conversation
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-3", "message": "I want to learn calculus"}'

# 2. Meta-request (should restart, not treat as topic)
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-3", "message": "actually, let me pick something different"}'

# Expected: Agent restarts, asks "What would you like to learn?"
```

#### **Test 4: Rejection with Correction**
```bash
# 1. Initial query
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-4", "message": "I want to learn physics"}'

# 2. Reject and correct
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-4", "message": "no, I meant chemistry"}'

# Expected: Agent understands correction, starts over with chemistry
```

#### **Test 5: Filler Words & Natural Language**
```bash
# Test various natural phrasings
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-5", "message": "teach me physics please"}'

curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-6", "message": "I want to learn about biology"}'

curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test-user-7", "message": "can you help me learn maths"}'

# Expected: All work correctly, filler words ignored
```

#### **Test 6: Error Handling**
```bash
# 1. Missing userId
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"message": "test"}'

# Expected: 400 error with clear message

# 2. Empty message
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d '{"userId": "test", "message": ""}'

# Expected: 400 error or graceful handling

# 3. Very long message (>1000 chars)
curl -X POST http://localhost:8080/api/agent/chat \
  -H 'Content-Type: application/json' \
  -d "{\"userId\": \"test\", \"message\": \"$(printf 'a%.0s' {1..1100})\"}"

# Expected: Either accepted or clear error
```

#### **Test 7: Performance & Metrics**
```bash
# 1. Check stats
curl http://localhost:8080/api/agent/stats/test-user-1 | jq

# Expected: totalConversations, totalToolCalls, avgResponseTime, etc.

# 2. Concurrent requests (use parallel curl or script)
for i in {1..10}; do
  curl -X POST http://localhost:8080/api/agent/chat \
    -H 'Content-Type: application/json' \
    -d "{\"userId\": \"test-user-$i\", \"message\": \"test $i\"}" &
done
wait

# Expected: All complete successfully, no crashes
```

---

### **Phase 4: Frontend Integration Testing (1-2h)**

**Setup:**
```bash
# Terminal 1: API
cd api && FF_AGENT_ORCHESTRATOR_V1=true npm run dev

# Terminal 2: Web
cd web && npm run dev
```

**Manual Tests:**

1. **Test in Browser (http://localhost:3000):**
   - Type: "I want to learn quantum physics"
   - Verify: Natural response, no errors
   - Type: "yes"
   - Verify: Confirmation response
   
2. **Test Meta-Requests:**
   - Type: "let's try something new"
   - Verify: Restarts conversation

3. **Test Refinement:**
   - Type: "science"
   - Verify: Agent asks for refinement
   - Type: "physics"
   - Verify: Agent narrows further

4. **Test Feature Flag Toggle:**
   - Disable `FF_AGENT_ORCHESTRATOR_V1` in `web/.env.local`
   - Restart web server
   - Verify: Falls back to workflow system
   - Enable flag again
   - Verify: Switches to agent

---

## ðŸ“Š **Test Coverage Summary**

| Category | Current | Target | Gap |
|----------|---------|--------|-----|
| **Unit Tests** | 14/26 (54%) | 26/26 (100%) | Fix timeouts + mocks |
| **Integration Tests** | 0 (none written) | 15+ scenarios | Write integration suite |
| **Manual Tests** | 0 (none documented) | 7 flows | Document manual tests |
| **Frontend Tests** | 0 (none written) | 4 scenarios | Test web integration |
| **Total Coverage** | **~30%** | **~95%** | **65% gap** |

---

## âœ… **Acceptance Criteria (Epic 13)**

### **Functional Requirements:**
- [ ] Agent responds to natural language queries
- [ ] Agent detects meta-requests ("learn something new")
- [ ] Agent handles affirmatives flexibly ("yes", "sounds good", "perfect")
- [ ] Agent detects granularity (subject/topic/module)
- [ ] Agent strips filler words ("please", "teach me")
- [ ] Agent handles rejection with correction ("no, I meant X")
- [ ] Agent stores conversation history (30-day retention)
- [ ] Agent tracks tool execution metrics

### **Technical Requirements:**
- [x] Database migrations applied (020, 021)
- [x] API routes registered (`/api/agent/*`)
- [x] Feature flag implemented (`FF_AGENT_ORCHESTRATOR_V1`)
- [ ] **Tests passing (26/26 unit, 15+ integration)**
- [ ] Response time <5s (p95)
- [ ] Cost per conversation <$0.01
- [ ] Graceful error handling
- [ ] Backward compatibility with workflow system

### **Documentation Requirements:**
- [x] Architecture guide
- [x] Tool development guide
- [x] API documentation
- [ ] **Test guide (needs update with fixes)**
- [ ] Deployment guide (needs creation)

---

## ðŸš€ **Recommended Action Plan**

### **Priority 1: Fix Existing Tests (Today - 2h)**
1. Separate unit vs integration tests
2. Mock OpenAI in unit tests
3. Fix conversation history test
4. Verify 26/26 passing

### **Priority 2: Manual Integration Testing (Today - 2h)**
1. Test 7 flows from Phase 3 above
2. Document results
3. Fix any bugs found

### **Priority 3: Add Missing Tests (Next - 3h)**
1. Tool execution tests
2. Advanced error handling
3. Conversation flows
4. Performance tests
5. Security tests

### **Priority 4: Frontend Testing (Next - 2h)**
1. Browser-based testing
2. Feature flag toggling
3. Error state handling
4. Loading states

### **Priority 5: Deployment Prep (Next - 1h)**
1. Create deployment guide
2. Document rollout strategy (10% â†’ 50% â†’ 100%)
3. Define monitoring metrics
4. Create rollback procedure

---

## ðŸ“ **Test Execution Checklist**

### **Today:**
- [ ] Fix test timeouts (increase to 30s or mock OpenAI)
- [ ] Fix conversation history test (add delay)
- [ ] Run full test suite - verify 26/26 passing
- [ ] Run 7 manual integration tests
- [ ] Document any bugs found

### **Next:**
- [ ] Add 20+ missing test scenarios
- [ ] Test frontend integration (4 scenarios)
- [ ] Performance/load testing
- [ ] Security testing
- [ ] Create deployment guide

---

## ðŸŽ¯ **Current Status: 95% Complete**

**What's Done:**
- âœ… Core implementation (100%)
- âœ… Documentation (100%)
- âœ… Database migrations (100%)
- âœ… API routes (100%)
- âœ… Feature flag (100%)
- âš ï¸ Tests (54% passing, need fixes)

**What's Needed:**
- âš ï¸ Fix 12 failing tests (timeouts + mocks)
- â³ Add 20+ missing test scenarios
- â³ Manual integration testing (7 flows)
- â³ Frontend integration testing (4 scenarios)
- â³ Deployment guide

**Estimated Time to 100% Complete:** 8-10 hours

---

**Next Step:** Fix failing tests (Priority 1) - should take ~2 hours.

